from unsloth import FastLanguageModel
import torch

# Load model Unsloth cÅ© cá»§a mÃ y
model_path = "output/qwen_mt_3B_v1" 
print("â³ Äang load Ä‘á»ƒ Merge...")
model, tokenizer = FastLanguageModel.from_pretrained(
    model_name = model_path,
    max_seq_length = 2048,
    dtype = None,
    load_in_4bit = True,
)

# Merge ra thÆ° má»¥c má»›i (dáº¡ng 16bit chuáº©n)
print("ğŸ’¾ Äang lÆ°u model chuáº©n (Merged) vÃ o 'output/merged_qwen_3b'...")
model.save_pretrained_merged("output/merged_qwen_3b", tokenizer, save_method = "merged_16bit")
print("âœ… Xong! Giá» dÃ¹ng cÃ¡i 'output/merged_qwen_3b' nÃ y Ä‘á»ƒ cháº¡y inference bao mÆ°á»£t!")