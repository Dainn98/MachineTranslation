import json
import random

# -----------------------------------------------------------
# Cáº¤U HÃŒNH INPUT
# -----------------------------------------------------------
vi_file_path = "input/clean_train.vi.txt"       # File tiáº¿ng Viá»‡t
en_file_path = "input/clean_train.en.txt"       # File tiáº¿ng Anh
jsonl_gloss_path = "input/bidirectional_train_data.jsonl" # File tá»« Ä‘iá»ƒn/viáº¿t táº¯t
output_file = "input/final_ultimate_train.jsonl" # TÃªn file káº¿t quáº£

# --- Cáº¤U HÃŒNH Sá» LÆ¯á»¢NG ---
SAMPLE_SIZE = 100000 

# Há»‡ sá»‘ nhÃ¢n báº£n cho file tá»« Ä‘iá»ƒn/viáº¿t táº¯t
GLOSS_MULTIPLIER = 20

training_data = []

# --- PHáº¦N 1: Äá»ŒC 2 FILE TEXT SONG SONG ---
print("â³ Äang Ä‘á»c 2 file text...")
with open(vi_file_path, "r", encoding="utf-8") as f_vi, \
     open(en_file_path, "r", encoding="utf-8") as f_en:
    
    vi_lines = [line.strip() for line in f_vi]
    en_lines = [line.strip() for line in f_en]

# Kiá»ƒm tra lá»‡ch dÃ²ng
if len(vi_lines) != len(en_lines):
    print(f"âš ï¸ Cáº¢NH BÃO: Sá»‘ dÃ²ng khÃ´ng khá»›p! VI: {len(vi_lines)} - EN: {len(en_lines)}")
    # Láº¥y sá»‘ dÃ²ng nhá» nháº¥t Ä‘á»ƒ zip
    min_len = min(len(vi_lines), len(en_lines))
    vi_lines = vi_lines[:min_len]
    en_lines = en_lines[:min_len]
else:
    print(f"âœ… Sá»‘ dÃ²ng khá»›p nhau tuyá»‡t Ä‘á»‘i: {len(vi_lines)} dÃ²ng.")

# GhÃ©p cáº·p
paired_lines = list(zip(en_lines, vi_lines))

# Láº¥y máº«u ngáº«u nhiÃªn (Sampling)
if SAMPLE_SIZE and SAMPLE_SIZE < len(paired_lines):
    print(f"âœ‚ï¸ Láº¥y ngáº«u nhiÃªn {SAMPLE_SIZE} cáº·p cÃ¢u Ä‘á»ƒ train...")
    sampled_pairs = random.sample(paired_lines, SAMPLE_SIZE)
else:
    sampled_pairs = paired_lines

# Convert sang format Chat
print("ğŸ”„ Äang convert sang format Qwen...")
for en_text, vi_text in sampled_pairs:
    if not en_text or not vi_text: continue # Bá» qua dÃ²ng trá»‘ng
    
    # Chiá»u En -> Vi
    training_data.append({
        "messages": [
            {"role": "system", "content": "You are a professional medical translator."},
            {"role": "user", "content": f"Translate to Vietnamese: {en_text}"},
            {"role": "assistant", "content": vi_text}
        ]
    })
    
    # Chiá»u Vi -> En (Dáº¡y luÃ´n chiá»u ngÆ°á»£c)
    training_data.append({
        "messages": [
            {"role": "system", "content": "You are a professional medical translator."},
            {"role": "user", "content": f"Translate to English: {vi_text}"},
            {"role": "assistant", "content": en_text}
        ]
    })

print(f"ğŸ“Š ÄÃ£ xong pháº§n data sáº¡ch. Sá»‘ máº«u: {len(training_data)}")

# --- PHáº¦N 2: TRá»˜N VÃ€ NHÃ‚N Báº¢N FILE Tá»ª ÄIá»‚N & VIáº¾T Táº®T ---
print("â³ Äang trá»™n file tá»« Ä‘iá»ƒn & viáº¿t táº¯t...")
gloss_data = []
try:
    with open(jsonl_gloss_path, "r", encoding="utf-8") as f:
        for line in f:
            gloss_data.append(json.loads(line))
            
    print(f"ğŸ’ª NhÃ¢n báº£n data GLOSS lÃªn {GLOSS_MULTIPLIER} láº§n ...")
    for _ in range(GLOSS_MULTIPLIER):
        training_data.extend(gloss_data)
        
except FileNotFoundError:
    print("âŒ Lá»–I: KhÃ´ng tÃ¬m tháº¥y file glossory.")

# --- PHáº¦N 3: LÆ¯U FILE CUá»I CÃ™NG ---
print("ğŸ”€ Äang trá»™n Ä‘á»u (Shuffle) láº§n cuá»‘i...")
random.shuffle(training_data)

with open(output_file, "w", encoding="utf-8") as f:
    for entry in training_data:
        f.write(json.dumps(entry, ensure_ascii=False) + "\n")

print(f"ğŸ‰ XONG! File train final: '{output_file}'")
print(f"ğŸ“ˆ Tá»•ng sá»‘ lÆ°á»£ng máº«u training: {len(training_data)}")